%\begin{figure*}
%        \includegraphics[width=\textwidth,height=5cm]{tensorflow-tika-integration}
%        \caption{Tika and Tensorflow Integration}
%        \label{fig:tf-tika-integration}
%\end{figure*}

\section{INTEGRATION} \label{sec:integration}
To integrate Tika and Tensorflow, we extended Tika's \texttt{Recogniser} interface which was introduced as part of our work in integrating named-entity recognition (NER) toolkits described in the prior section. Our new interface was called \texttt{ObjectRecogniser}. The goal of \texttt{ObjectRecogniser} is to facilitate multiple implementations that extend beyond Tensorflow and may include other deep learning and object recognition frameworks. The main component of the interface contract is a function that accepts image data and returns a list of \texttt{RecognisedObject}s.

For our initial implementation of \texttt{ObjectRecogniser}, we created a Python-based command line (CLI) tool as an entry point to Tensorflow's image recognition network. This tool inspected the environment for its requirements (including the Tensorflow command line tool) and when its requirements were not met it failed and reported the failure. Apache Tika executed in the JVM process where a new native process was created and destroyed. Tika then passed the image path as a command line argument to the tool as shown in Figure \ref{fig:tf-tika-integration} (a). The tool parsed the arguments, passed the content to the Tensorflow network, and reported the results by printing it to standard output. Tika parser then reads the result from its output stream. We did not extend Tensorflow's existing ImageNet/Inception model training and simply used it off-the-shelf and pre-configured in the Tensorflow Python program.

Vendors recommend the Java Native Interface (JNI) for integrating native code libraries to Java frameworks\cite{gordon1998essential}. JNI acts as glue between bytecode instructions that run within the Java Virtual Machine (JVM) and the native code instructions that run directly on the CPU. Theoretically, this is the best way of merging the JVM world with native code. At runtime, the bytecode of Tika (caller) and native code of Tensorflow (callee) runs within a single process from the operating system's perspective as shown in Figure \ref{fig:tf-tika-integration} (b).

The developers of the Tensorflow framework recommended using gRPC-based integration for the production systems\cite{goog-tfserve}. gRPC is a client-server based architecture in which caller acts as an RPC client and callee operates as a server in a different address space. Unlike traditional RPC frameworks, gRPC is a high-performance, high-CPU, and bandwidth efficient transport on top of HTTP/2 that supports full duplex streaming\cite{about-grpc}. In our case, we embedded gRPC client in Tika JVM and exported Tensorflow image recognition capabilities as remote procedures via gRPC service. We used Tensorflow Serving, a gRPC server implemented in C++, and also created a Docker container to host it.  Collecting the needed libraries to build the gRPC interface proved to be a non-trivial effort, and rather than require users of our Tika and Tensorflow integration to install these libraries, we also investigated building a Representation State Transfer (REST) interface \cite{Fielding:2000:ASD:932295}.

REST is a client-server architecture paradigm for connecting heterogeneous systems without the need of states \cite[Chapter~5]{Fielding:2000:ASD:932295}. The REST application programming interfaces (API) is powered by the HyperText Transfer Protocol (HTTP) which abstracts the complexities of Transmission Control Protocol.
We created a REST API for Tensorflow image recognition using Python Flask. The Flask-based HTTP service registered a TCP port and offered HTTP API endpoints as shown in Figure \ref{fig:tf-tika-integration} (d), and the REST interface had the advantage of minimizing client dependencies for using our framework. REST clients are lightweight and have easily installable dependencies across all major programming languages. Our REST API endpoint accepted HTTP POST requests with image data in the request body. This service loaded the Inception v3 \cite{SzegedyVISW15} model during the initialization phase and held the model in memory for reuse during the future HTTP Requests.

% \begin{figure}[h]
%     \centering
%     \includegraphics[width=\columnwidth]{military_dog}
%     \caption{Military Person with a German Shepherd Dog \newline Courtesy: Wikimedia Commons}
%     \label{fig:military-dog}
% \end{figure}

% The REST API, upon recognizing the objects in the image \ref{fig:military-dog}, returned the response in the JSON format with the following structure:

% \begin{lstlisting}[language=json, label=code:json-output,
% 	frame=single, xleftmargin=5.0pt, xrightmargin=5.0pt,
%     caption=JSON Response from REST API]
% {
%   "confidence": [ 0.362026, 0.130613],
%   "classnames": [
%     "German shepherd, alsatian",
%     "military uniform"
%   ],
%   "classids": [211, 866 ],
%   "time": {
%     "read": 1,
%     "units": "ms",
%     "classification": 257
%   }
% }
% \end{lstlisting}

On the other side of the system, we implemented the class \texttt{TensorflowRESTRecogniser}, which used HTTP Client to communicate with the REST API. This implementation of \texttt{ObjectRecogniser} converted the image data to an HTTP POST request with multipart form data and sent it to REST API. It parsed the JSON response to retrieve the object names, IDs and confidence scores. We also created a Docker specification for bootstrapping the Tensorflow image recognition REST API for semi-automated deployment of the system. This presents a user-friendly client and server for Tensorflow Tika integration in which all needed dependencies and capabilities for the integration are automatically provided.

%\includegraphics[scale=0.40]{tika-tflow-rest-design}
