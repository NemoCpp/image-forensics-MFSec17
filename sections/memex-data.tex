\section{Memex Data Collection}
\label{sec:memex-datacollection}
Several web crawlers were used to discover and retrieve information from the websites.
Along with the general-purpose web crawlers, there was specialized crawler for the retrieval of dark data using TOR protocol \cite{} and also specialized in the retrieval of dynamic AJAX content guarded by login forms. The fetched data were cached within the system for analysis due to the ephemeral nature of the content at the sources.

% \subsection{Memex Dataset} \label{sec:memex-dataset}
The dataset used in our experiment was a subset of memex dataset in public domain. It contained 7.2 million documents in the illegal weapon sales domain in which 1.4 million documents were images. We had analyzed the textual documents and the named entities separately in a different experiment using named entity recognition models and extractors for people, location, organization, weapon name, and weapon-types. In this experiment, we were interested in labeling images by classifying them into various classes. Usually, web crawlers fetch all resources linked in the web pages and hence classification was an important pre-processing to remove noise for the later analysis.